{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcee23bd",
   "metadata": {},
   "source": [
    "# Visual Wake Word Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a258f29",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries\n",
    "\n",
    "This cell imports essential libraries: Gradio for the interface, OpenCV for image processing, the Akida library for model execution, and NumPy and Plotly for data handling and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35785368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.conda/envs/akida_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-07-31 14:45:37.554567: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-31 14:45:37.575472: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-31 14:45:37.575489: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-31 14:45:37.576063: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-31 14:45:37.579693: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-31 14:45:38.057854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/guest/.conda/envs/akida_env/lib/python3.11/site-packages/onnxscript/converter.py:816: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "\n",
    "from cnn2snn import set_akida_version, AkidaVersion\n",
    "import akida\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5d0b6",
   "metadata": {},
   "source": [
    "### Gauge Creation Function\n",
    "\n",
    "Defines a function using Plotly to create a gauge visualization for metrics such as frames per second during image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31006aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gauge(value):\n",
    "    fig = go.Figure(go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=value,\n",
    "        gauge={'axis': {'range': [0, 30]}},\n",
    "        domain={'x': [0, 1], 'y': [0, 1]},\n",
    "    ))\n",
    "    fig.update_layout(width=400, height=300)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944ee12",
   "metadata": {},
   "source": [
    "### Softmax Function for Arrays\n",
    "\n",
    "Implements a softmax function to convert model outputs into probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0507dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax for an array of values\n",
    "def softmaxArray(values):\n",
    "    # Assuming array shape is (1, 1, 1, x), flatten to get the values\n",
    "    values = values.ravel()\n",
    "    exp_values = np.exp(values)\n",
    "    sum_exp = np.sum(exp_values)\n",
    "    softmax_values = exp_values / sum_exp\n",
    "    return softmax_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e976a9",
   "metadata": {},
   "source": [
    "### Image Configuration and Output Decoding\n",
    "\n",
    "Sets up image parameters and label names, and includes a function to preprocess images and decode predictions into readable labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48246e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = 96\n",
    "image_y = 96\n",
    "image_z = 3\n",
    "labels = [\"no person\", \"person\"]\n",
    "def decodeOutput(inp):\n",
    "        global akida_model\n",
    "        inp = cv2.resize(inp, (image_x, image_y))\n",
    "        inp = inp.reshape((-1, image_x, image_y, image_z))\n",
    "        timer_start = time.time()\n",
    "        predictions = softmaxArray(akida_model.predict(inp))\n",
    "        frame_time = time.time() - timer_start\n",
    "        fps = 1 / frame_time if frame_time > 0 else 0\n",
    "        confidences = {labels[i]: predictions[i] for i in range(len(predictions))}\n",
    "\n",
    "        return confidences, fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8830e8d",
   "metadata": {},
   "source": [
    "### Image Classification Wrapper\n",
    "\n",
    "A function that processes an image, decodes it, and returns classification confidences with a gauge visualization of processing speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bccd78e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(inp):\n",
    "\n",
    "  confidences, fps = decodeOutput(inp)\n",
    "\n",
    "  return confidences, create_gauge(round(fps, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5afcdd6",
   "metadata": {},
   "source": [
    "### Load Pre-trained Model\n",
    "\n",
    "Loads a pre-trained quantized model for visual wake word detection via `akida_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc99fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model Summary                 \n",
      "______________________________________________\n",
      "Input shape  Output shape  Sequences  Layers\n",
      "==============================================\n",
      "[96, 96, 3]  [1, 1, 2]     1          26    \n",
      "______________________________________________\n",
      "\n",
      "___________________________________________________________________\n",
      "Layer (type)                       Output shape  Kernel shape    \n",
      "\n",
      "================= SW/conv_0-dequantizer (Software) ================\n",
      "\n",
      "conv_0 (InputConv2D)               [48, 48, 8]   (3, 3, 3, 8)    \n",
      "___________________________________________________________________\n",
      "conv_1 (Conv2D)                    [48, 48, 16]  (3, 3, 8, 16)   \n",
      "___________________________________________________________________\n",
      "conv_2 (Conv2D)                    [24, 24, 32]  (3, 3, 16, 32)  \n",
      "___________________________________________________________________\n",
      "conv_3 (Conv2D)                    [24, 24, 32]  (3, 3, 32, 32)  \n",
      "___________________________________________________________________\n",
      "dw_separable_4 (DepthwiseConv2D)   [12, 12, 32]  (3, 3, 32, 1)   \n",
      "___________________________________________________________________\n",
      "pw_separable_4 (Conv2D)            [12, 12, 64]  (1, 1, 32, 64)  \n",
      "___________________________________________________________________\n",
      "dw_separable_5 (DepthwiseConv2D)   [12, 12, 64]  (3, 3, 64, 1)   \n",
      "___________________________________________________________________\n",
      "pw_separable_5 (Conv2D)            [12, 12, 64]  (1, 1, 64, 64)  \n",
      "___________________________________________________________________\n",
      "dw_separable_6 (DepthwiseConv2D)   [6, 6, 64]    (3, 3, 64, 1)   \n",
      "___________________________________________________________________\n",
      "pw_separable_6 (Conv2D)            [6, 6, 128]   (1, 1, 64, 128) \n",
      "___________________________________________________________________\n",
      "dw_separable_7 (DepthwiseConv2D)   [6, 6, 128]   (3, 3, 128, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_7 (Conv2D)            [6, 6, 128]   (1, 1, 128, 128)\n",
      "___________________________________________________________________\n",
      "dw_separable_8 (DepthwiseConv2D)   [6, 6, 128]   (3, 3, 128, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_8 (Conv2D)            [6, 6, 128]   (1, 1, 128, 128)\n",
      "___________________________________________________________________\n",
      "dw_separable_9 (DepthwiseConv2D)   [6, 6, 128]   (3, 3, 128, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_9 (Conv2D)            [6, 6, 128]   (1, 1, 128, 128)\n",
      "___________________________________________________________________\n",
      "dw_separable_10 (DepthwiseConv2D)  [6, 6, 128]   (3, 3, 128, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_10 (Conv2D)           [6, 6, 128]   (1, 1, 128, 128)\n",
      "___________________________________________________________________\n",
      "dw_separable_11 (DepthwiseConv2D)  [6, 6, 128]   (3, 3, 128, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_11 (Conv2D)           [6, 6, 128]   (1, 1, 128, 128)\n",
      "___________________________________________________________________\n",
      "dw_separable_12 (DepthwiseConv2D)  [3, 3, 128]   (3, 3, 128, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_12 (Conv2D)           [3, 3, 256]   (1, 1, 128, 256)\n",
      "___________________________________________________________________\n",
      "dw_separable_13 (DepthwiseConv2D)  [3, 3, 256]   (3, 3, 256, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_13 (Conv2D)           [1, 1, 256]   (1, 1, 256, 256)\n",
      "___________________________________________________________________\n",
      "classifier (Dense1D)               [1, 1, 2]     (256, 2)        \n",
      "___________________________________________________________________\n",
      "dequantizer (Dequantizer)          [1, 1, 2]     N/A             \n",
      "___________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from akida_models.model_io import load_model\n",
    "akida_model = load_model(\"models/akidanet_vww_i8_w4_a4.fbz\")\n",
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0efcf",
   "metadata": {},
   "source": [
    "Map the `akida_model` onto the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ea800d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: ['fpga-1691']\n",
      "BC.A2.001.000\n",
      "Mapping to Akida device fpga-1691.\n"
     ]
    }
   ],
   "source": [
    "with set_akida_version(AkidaVersion.v2):\n",
    "            devices = akida.devices()\n",
    "            if len(devices) > 0:\n",
    "                print(f'Available devices: {[dev.desc for dev in devices]}')\n",
    "                device = devices[0]\n",
    "                print(device.version)\n",
    "                try:\n",
    "                    akida_model.map(device)\n",
    "                    print(f\"Mapping to Akida device {device.desc}.\")\n",
    "                    mappedDevice = device.version\n",
    "                except Exception as e:\n",
    "                    print(\"Model not compatible with FPGA. Running on CPU.\")\n",
    "                    mappedDevice = \"CPU\"\n",
    "            else:\n",
    "                print(\"No Akida devices found, running on CPU.\")\n",
    "                mappedDevice = \"CPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29462c7-a75f-479f-a260-8ddc9a6332c4",
   "metadata": {},
   "source": [
    "### Model Summary After Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ddc6a3-7e8c-4f66-a896-7c93fe7fcc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Model Summary                                     \n",
      "_______________________________________________________________________________________\n",
      "Input shape  Output shape  Sequences  Layers  NPs  Skip DMAs  External Memory (Bytes)\n",
      "=======================================================================================\n",
      "[96, 96, 3]  [1, 1, 2]     1          26      24   0          528                    \n",
      "_______________________________________________________________________________________\n",
      "\n",
      "_________________________\n",
      "Component (type)  Count\n",
      "=========================\n",
      "HRC               1    \n",
      "_________________________\n",
      "CNP1              23   \n",
      "_________________________\n",
      "FNP2              1    \n",
      "_________________________\n",
      "\n",
      "            External Memory Summary            \n",
      "_______________________________________________\n",
      "Layer (type)          External Memory (Bytes)\n",
      "===============================================\n",
      "classifier (Dense1D)  528                    \n",
      "_______________________________________________\n",
      "\n",
      "_______________________________________________________________________________\n",
      "Layer (type)                       Output shape  Kernel shape      Components\n",
      "\n",
      "============ HW/conv_0-dequantizer (Hardware) - size: 193396 bytes ============\n",
      "\n",
      "conv_0 (InputConv2D)               [48, 48, 8]   (3, 3, 3, 8)      1 HRC     \n",
      "_______________________________________________________________________________\n",
      "conv_1 (Conv2D)                    [48, 48, 16]  (3, 3, 8, 16)     1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "conv_2 (Conv2D)                    [24, 24, 32]  (3, 3, 16, 32)    1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "conv_3 (Conv2D)                    [24, 24, 32]  (3, 3, 32, 32)    1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "dw_separable_4 (DepthwiseConv2D)   [12, 12, 32]  (3, 3, 32, 1)     1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "pw_separable_4 (Conv2D)            [12, 12, 64]  (1, 1, 32, 64)    1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "dw_separable_5 (DepthwiseConv2D)   [12, 12, 64]  (3, 3, 64, 1)     1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "pw_separable_5 (Conv2D)            [12, 12, 64]  (1, 1, 64, 64)    1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "dw_separable_6 (DepthwiseConv2D)   [6, 6, 64]    (3, 3, 64, 1)     1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "pw_separable_6 (Conv2D)            [6, 6, 128]   (1, 1, 64, 128)   1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "dw_separable_7 (DepthwiseConv2D)   [6, 6, 128]   (3, 3, 128, 1)    1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "pw_separable_7 (Conv2D)            [6, 6, 128]   (1, 1, 128, 128)  1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "dw_separable_8 (DepthwiseConv2D)   [6, 6, 128]   (3, 3, 128, 1)    1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "pw_separable_8 (Conv2D)            [6, 6, 128]   (1, 1, 128, 128)  1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "dw_separable_9 (DepthwiseConv2D)   [6, 6, 128]   (3, 3, 128, 1)    1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "pw_separable_9 (Conv2D)            [6, 6, 128]   (1, 1, 128, 128)  1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "dw_separable_10 (DepthwiseConv2D)  [6, 6, 128]   (3, 3, 128, 1)    1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "pw_separable_10 (Conv2D)           [6, 6, 128]   (1, 1, 128, 128)  1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "dw_separable_11 (DepthwiseConv2D)  [6, 6, 128]   (3, 3, 128, 1)    1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "pw_separable_11 (Conv2D)           [6, 6, 128]   (1, 1, 128, 128)  1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "dw_separable_12 (DepthwiseConv2D)  [3, 3, 128]   (3, 3, 128, 1)    1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "pw_separable_12 (Conv2D)           [3, 3, 256]   (1, 1, 128, 256)  1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "dw_separable_13 (DepthwiseConv2D)  [3, 3, 256]   (3, 3, 256, 1)    1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "pw_separable_13 (Conv2D)           [1, 1, 256]   (1, 1, 256, 256)  1 CNP1    \n",
      "_______________________________________________________________________________\n",
      "classifier (Dense1D)               [1, 1, 2]     (256, 2)          1 FNP2    \n",
      "_______________________________________________________________________________\n",
      "dequantizer (Dequantizer)          [1, 1, 2]     N/A               N/A       \n",
      "_______________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ee5a7",
   "metadata": {},
   "source": [
    "### Gradio Interface Setup\n",
    "\n",
    "Creates a Gradio interface to capture webcam images, display device information, and stream classified images using the Akida model. The interface shows live predictions and frame processing speeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b0e8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gradio.components.label.Label object at 0x7be2c8f3eed0>\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theme = gr.themes.Base(\n",
    "    text_size=\"sm\",\n",
    "    spacing_size=\"sm\",\n",
    "    radius_size=\"sm\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(\n",
    "    title=\"Brainchip\",\n",
    "    fill_width=True,\n",
    "    fill_height=True,\n",
    "    delete_cache=[180, 600],\n",
    "    theme=theme\n",
    ") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "        <h1 style=\"text-align: center;\">Akida Cloud</h1>\n",
    "        <br>\n",
    "        \"\"\")\n",
    "    with gr.Row():\n",
    "        gr.Markdown(\"## Image Classification\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_img = gr.Image(sources=[\"webcam\"], type=\"numpy\")\n",
    "            gr.Markdown(\"**ℹ️ Please press the 'Record' button to start inference.**\")\n",
    "        with gr.Column():\n",
    "            gr.Markdown(f\"\"\"Device: {mappedDevice}\"\"\")\n",
    "            output_label = gr.Label(num_top_classes=3)\n",
    "            print(output_label)\n",
    "            plot = gr.Plot(label=\"Frames per second\")\n",
    "        dep = input_img.stream(classify_image, [input_img], [output_label, plot],\n",
    "                                time_limit=30, stream_every=0.1, concurrency_limit=30)        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a98800-c506-4355-8bd7-5b04d94e4fcb",
   "metadata": {},
   "source": [
    "#### Note: Once you’ve finished running the notebook, ***\"Uncomment and run the cell below\"*** to release the device and free it up for further experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85274cf3-2ad3-4f67-81c3-cbd38e0fe336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os._exit(00)"
   ]
  },
  {
   "attachments": {
    "b5ba76da-de55-4da5-81ca-4519b7f3021b.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c4fd993f-bdf5-44e6-92d0-cc04a371931c",
   "metadata": {},
   "source": [
    "#### You can also use this button to reset your kernel\n",
    "\n",
    "![image.png](attachment:b5ba76da-de55-4da5-81ca-4519b7f3021b.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53cb95-ef38-4d4d-b8e8-8a7cbf3b9fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
