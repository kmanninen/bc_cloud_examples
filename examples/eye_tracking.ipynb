{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e0e99e",
   "metadata": {},
   "source": [
    "# Eye Tracking Example\n",
    "\n",
    "This example demonstrates Akida's eye tracking capabilities using the Brainchip's spatiotemporal architecture.\n",
    "\n",
    "The notebook below is derived from the [\"Efficient online eye tracking with a lightweight spatiotemporal network and event cameras\"](https://doc.brainchipinc.com/examples/spatiotemporal/plot_1_eye_tracking_cvpr.html) on the Brainchip Developer MetaTF website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d741fc2",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries\n",
    "\n",
    "This cell imports essential libraries: matplotplib for event visualizations, the Akida libraries for model execution.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c43cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 14:51:11.666786: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-31 14:51:11.687719: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-31 14:51:11.687736: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-31 14:51:11.688319: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-31 14:51:11.692264: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-31 14:51:12.142258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/guest/.conda/envs/akida_env/lib/python3.11/site-packages/onnxscript/converter.py:816: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from cnn2snn import set_akida_version, AkidaVersion\n",
    "import akida\n",
    "from akida_models.tenn_spatiotemporal.eye_preprocessing import preprocess_data\n",
    "from akida_models.tenn_spatiotemporal.eye_losses import process_detector_prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a72c1f",
   "metadata": {},
   "source": [
    "### Load and segment the sample events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe2773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_segment_npy(file_path, time_window_us=10_000, segment_duration_us=500_000):\n",
    "    \"\"\"\n",
    "    Loads event data from a structured .npy file, splits it into 500ms segments,\n",
    "    and converts each segment into model-compatible frames using preprocess_data.\n",
    "    Args:\n",
    "        file_path (str): Path to the .npy event file (with fields: 'p', 'x', 'y', 't').\n",
    "        preprocess_data_fn (callable): preprocess_data function to apply per segment.\n",
    "        time_window_us (int): Time window per frame (default: 10,000µs).\n",
    "        segment_duration_us (int): Duration of each segment in microseconds (default: 500,000µs).\n",
    "    Returns:\n",
    "        list of tf.Tensor: List of processed frame tensors.\n",
    "    \"\"\"\n",
    "    # Load structured event array\n",
    "    data = np.load(file_path)\n",
    "    # print(f\"Loaded {data.shape[0]} events\")\n",
    "\n",
    "    # Convert structured fields to float32 arrays\n",
    "    p = data['p'].astype('float32')\n",
    "    x = data['x'].astype('float32')\n",
    "    y = data['y'].astype('float32')\n",
    "    t = data['t'].astype('float32')\n",
    "\n",
    "    # Prepare stacked event tensor (4, N)\n",
    "    trial = tf.stack([p, x, y, t], axis=0)\n",
    "\n",
    "    # Time range\n",
    "    t_start = t[0]\n",
    "    t_end = t[-1]\n",
    "\n",
    "    frames_list = []\n",
    "    segment_list = []\n",
    "\n",
    "    current_time = t_start\n",
    "    while current_time + segment_duration_us <= t_end:\n",
    "        # Get indices for the current 500ms window\n",
    "        start_idx = np.searchsorted(t, current_time, side='left')\n",
    "        end_idx = np.searchsorted(t, current_time + segment_duration_us, side='right')\n",
    "\n",
    "        # Slice event segment\n",
    "        segment = tf.stack([\n",
    "            p[start_idx:end_idx],\n",
    "            x[start_idx:end_idx],\n",
    "            y[start_idx:end_idx],\n",
    "            t[start_idx:end_idx]\n",
    "        ], axis=0)\n",
    "\n",
    "        # Dummy label (e.g. center)\n",
    "        label = tf.convert_to_tensor([[0.5, 0.5, 0]], dtype=tf.float32)\n",
    "\n",
    "        # Preprocess segment into frames\n",
    "        frames, _ = preprocess_data(\n",
    "            events=segment,\n",
    "            label=label,\n",
    "            train_mode=False,\n",
    "            frames_per_segment=1,\n",
    "            spatial_downsample=(6, 6),\n",
    "            time_window=time_window_us\n",
    "        )\n",
    "\n",
    "        frames_list.append(frames)\n",
    "        segment_list.append(segment)\n",
    "        current_time += segment_duration_us\n",
    "\n",
    "    print(f\"Processed {len(frames_list)} segments of 500ms each.\")\n",
    "    return frames_list, segment_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95e6fd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 22 segments of 500ms each.\n",
      "Loaded data with 22 frames, 80×106 pixels, 2 channels\n"
     ]
    }
   ],
   "source": [
    "frames_all, segment_all = load_and_segment_npy(\"eye_tracking_event_examples.npy\")\n",
    "n_frames = len(frames_all)\n",
    "N, H, W, n_ch = frames_all[0].shape\n",
    "print(f\"Loaded data with {n_frames} frames, {H}×{W} pixels, {n_ch} channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb23b79",
   "metadata": {},
   "source": [
    "### Load Pre-trained model\n",
    "\n",
    "Loads a pre-trained quantized model for eye tracking via `akida_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b83564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input shape: [80, 106, 2]\n"
     ]
    }
   ],
   "source": [
    "import akida_models\n",
    "from akida_models.model_io import load_model\n",
    "model = load_model(\"models/tenn_spatiotemporal_eye_buffer_i8_w8_a8.fbz\")\n",
    "print(f\"Model input shape: {model.input_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf653de",
   "metadata": {},
   "source": [
    "Map the `akida_model` onto the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8b5460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: ['fpga-1691']\n",
      "BC.A2.001.000\n",
      "Mapping to Akida device fpga-1691.\n"
     ]
    }
   ],
   "source": [
    "with set_akida_version(AkidaVersion.v2):\n",
    "    devices = akida.devices()\n",
    "    if len(devices) > 0:\n",
    "        print(f'Available devices: {[dev.desc for dev in devices]}')\n",
    "        device = devices[0]\n",
    "        print(device.version)\n",
    "        try:\n",
    "            model.map(device)\n",
    "            print(f\"Mapping to Akida device {device.desc}.\")\n",
    "            mappedDevice = device.version\n",
    "        except Exception as e:\n",
    "            print(\"Model not compatible with FPGA. Running on CPU.\")\n",
    "            mappedDevice = \"CPU\"\n",
    "    else:\n",
    "        print(\"No Akida devices found, running on CPU.\")\n",
    "        mappedDevice = \"CPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db70ab1-31d6-47a2-b865-28acdda45b39",
   "metadata": {},
   "source": [
    "### Model Summary After Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0521a34f-db06-47a1-8f0d-97942b947cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Model Summary                                      \n",
      "________________________________________________________________________________________\n",
      "Input shape   Output shape  Sequences  Layers  NPs  Skip DMAs  External Memory (Bytes)\n",
      "========================================================================================\n",
      "[80, 106, 2]  [3, 4, 3]     1          20      36   6          307008                 \n",
      "________________________________________________________________________________________\n",
      "\n",
      "_________________________\n",
      "Component (type)  Count\n",
      "=========================\n",
      "CNP1              23   \n",
      "_________________________\n",
      "SKIP_DMA_STORE    6    \n",
      "_________________________\n",
      "TNP_B             13   \n",
      "_________________________\n",
      "SKIP_DMA_LOAD     6    \n",
      "_________________________\n",
      "\n",
      "                      External Memory Summary                       \n",
      "____________________________________________________________________\n",
      "Layer (type)                               External Memory (Bytes)\n",
      "====================================================================\n",
      "convt_full_0 (BufferTempConv)              101760                 \n",
      "____________________________________________________________________\n",
      "convt_full_1 (BufferTempConv)              103680                 \n",
      "____________________________________________________________________\n",
      "convt_full_2 (BufferTempConv)              53760                  \n",
      "____________________________________________________________________\n",
      "convt_dw_3 (DepthwiseBufferTempConv)       20160                  \n",
      "____________________________________________________________________\n",
      "convt_dw_4 (DepthwiseBufferTempConv)       9216                   \n",
      "____________________________________________________________________\n",
      "HEAD_convt_dw_4 (DepthwiseBufferTempConv)  18432                  \n",
      "____________________________________________________________________\n",
      "\n",
      "_________________________________________________________________________________________________________________________\n",
      "Layer (type)                               Output shape  Kernel shape      Components                                  \n",
      "\n",
      "============================== HW/convs_full_0-dequantizer (Hardware) - size: 307856 bytes ==============================\n",
      "\n",
      "convs_full_0 (Conv2D)                      [40, 53, 8]   (3, 3, 2, 8)      2 CNP1                                      \n",
      "_________________________________________________________________________________________________________________________\n",
      "convt_full_0 (BufferTempConv)              [40, 53, 16]  (1, 1, 40, 16)    2 TNP_B + 1 SKIP_DMA_STORE + 1 SKIP_DMA_LOAD\n",
      "_________________________________________________________________________________________________________________________\n",
      "convs_full_1 (Conv2D)                      [20, 27, 32]  (3, 3, 16, 32)    1 CNP1                                      \n",
      "_________________________________________________________________________________________________________________________\n",
      "convt_full_1 (BufferTempConv)              [20, 27, 48]  (1, 1, 160, 48)   2 TNP_B + 1 SKIP_DMA_STORE + 1 SKIP_DMA_LOAD\n",
      "_________________________________________________________________________________________________________________________\n",
      "convs_full_2 (Conv2D)                      [10, 14, 64]  (3, 3, 48, 64)    1 CNP1                                      \n",
      "_________________________________________________________________________________________________________________________\n",
      "convt_full_2 (BufferTempConv)              [10, 14, 80]  (1, 1, 320, 80)   1 TNP_B + 1 SKIP_DMA_STORE + 1 SKIP_DMA_LOAD\n",
      "_________________________________________________________________________________________________________________________\n",
      "convs_dw_3 (DepthwiseConv2D)               [5, 7, 80]    (3, 3, 80, 1)     1 CNP1                                      \n",
      "_________________________________________________________________________________________________________________________\n",
      "convs_pw_3 (Conv2D)                        [5, 7, 96]    (1, 1, 80, 96)    2 CNP1                                      \n",
      "_________________________________________________________________________________________________________________________\n",
      "convt_dw_3 (DepthwiseBufferTempConv)       [5, 7, 96]    (1, 1, 5, 96)     2 TNP_B + 1 SKIP_DMA_STORE + 1 SKIP_DMA_LOAD\n",
      "========================================================= pass 2 ========================================================\n",
      "convt_pw_3 (Conv2D)                        [5, 7, 112]   (1, 1, 96, 112)   2 CNP1                                      \n",
      "_________________________________________________________________________________________________________________________\n",
      "convs_dw_4 (DepthwiseConv2D)               [3, 4, 112]   (3, 3, 112, 1)    2 CNP1                                      \n",
      "_________________________________________________________________________________________________________________________\n",
      "convs_pw_4 (Conv2D)                        [3, 4, 128]   (1, 1, 112, 128)  2 CNP1                                      \n",
      "_________________________________________________________________________________________________________________________\n",
      "convt_dw_4 (DepthwiseBufferTempConv)       [3, 4, 128]   (1, 1, 5, 128)    2 TNP_B + 1 SKIP_DMA_STORE + 1 SKIP_DMA_LOAD\n",
      "_________________________________________________________________________________________________________________________\n",
      "convt_pw_4 (Conv2D)                        [3, 4, 256]   (1, 1, 128, 256)  3 CNP1                                      \n",
      "_________________________________________________________________________________________________________________________\n",
      "HEAD_convt_dw_4 (DepthwiseBufferTempConv)  [3, 4, 256]   (1, 1, 5, 256)    4 TNP_B + 1 SKIP_DMA_STORE + 1 SKIP_DMA_LOAD\n",
      "_________________________________________________________________________________________________________________________\n",
      "HEAD_convt_pw_4 (Conv2D)                   [3, 4, 256]   (1, 1, 256, 256)  3 CNP1                                      \n",
      "_________________________________________________________________________________________________________________________\n",
      "HEAD_convs_dw_4 (DepthwiseConv2D)          [3, 4, 256]   (3, 3, 256, 1)    3 CNP1                                      \n",
      "_________________________________________________________________________________________________________________________\n",
      "HEAD_convs_pw_4 (Conv2D)                   [3, 4, 3]     (1, 1, 256, 3)    1 CNP1                                      \n",
      "_________________________________________________________________________________________________________________________\n",
      "dequantizer (Dequantizer)                  [3, 4, 3]     N/A               N/A                                         \n",
      "_________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec0b442",
   "metadata": {},
   "source": [
    "### Perform eye tracking inference against sample event data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e207083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if n_ch == 2:\n",
    "    # e.g. channel 0 = red, channel 1 = blue\n",
    "    colors = np.array([[255, 0, 0], [0, 0, 255]], dtype=np.uint8)\n",
    "else:\n",
    "    # fallback: pick from matplotlib’s tab10 palette\n",
    "    import matplotlib\n",
    "    cmap = matplotlib.cm.get_cmap('tab10', n_ch)\n",
    "    colors = (cmap(range(n_ch))[:, :3] * 255).astype(np.uint8)\n",
    "\n",
    "# 3) Create one figure & axis to reuse\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "frame_number = 0\n",
    "\n",
    "# Define the size of the cross\n",
    "cross_size = 3\n",
    "\n",
    "# 4) Loop over frames, updating in place\n",
    "for f in frames_all:\n",
    "    frame_number += 1\n",
    "    # 4a) start from a mid-gray background\n",
    "    frame_vis = np.full((H, W, 3), 128, dtype=np.uint8)\n",
    "\n",
    "    f_np = f.numpy() if isinstance(f, tf.Tensor) else f  # Ensure f is a numpy array\n",
    "    frame = f_np[0]\n",
    "\n",
    "    # predict using the model\n",
    "    pred = model.predict(f_np)\n",
    "\n",
    "    pred = process_detector_prediction(tf.expand_dims(pred, 0))\n",
    "\n",
    "    y_pred_x = pred[:, 1] * W\n",
    "    y_pred_y = pred[:, 0] * H\n",
    "\n",
    "\n",
    "    # Convert to NumPy scalars\n",
    "    cx = int(y_pred_x.numpy().flatten()[0])\n",
    "    cy = int(y_pred_y.numpy().flatten()[0])\n",
    "\n",
    "    # 4b) paint each channel’s “events” on top\n",
    "    for ch in range(n_ch):\n",
    "        \n",
    "        mask = frame[ :, :, ch] > 0   # assuming >0 marks an event\n",
    "\n",
    "        pred_mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=bool)\n",
    "        # Draw a cross centered at (x, y)\n",
    "        for i in range(-cross_size, cross_size + 1):\n",
    "            if 0 <= cx + i < frame.shape[0]:\n",
    "                pred_mask[cx + i, cy] = True\n",
    "            if 0 <= cy + i < frame.shape[1]:\n",
    "                pred_mask[cx, cy + i] = True\n",
    "\n",
    "        frame_vis[mask] = colors[ch]\n",
    "        frame_vis[pred_mask] = [255, 255, 0]\n",
    "    \n",
    "    # 4c) update the image\n",
    "    ax.clear()\n",
    "    ax.imshow(frame_vis)\n",
    "    ax.set_title(f'Frame {frame_number}/{n_frames}')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # 4d) redraw the same window\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "    time.sleep(0.01)   # adjust playback speed\n",
    "\n",
    "# 5) close when done\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd77db0-699b-4244-9414-51f366ac452c",
   "metadata": {},
   "source": [
    "### Model Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc01461e-e354-4427-bc27-f4cf3d39dff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fps: 15.38, inference clock: 1618856, program clock: 3248046"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eeae52-6676-4278-ba89-809a066aa586",
   "metadata": {},
   "source": [
    "#### Note: Once you’ve finished running the notebook, ***\"Uncomment and run the cell below\"*** to release the device and free it up for further experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "620869d9-58c7-46c3-b816-b57f80feb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os._exit(00)"
   ]
  },
  {
   "attachments": {
    "5db9e2e8-18f9-43d0-89a6-98c3bdbce362.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAAwCAYAAADw1toQAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAA+KSURBVHhe7d19bBR1Hsfx9+xzu/SJlj5QbEtZWyzB1gMraPRycOqJOcA7OQ44kRwafDg1kBiJonKH5kLiQ0TB5C7BBETxAQVFOHkQQ0tPLIKV0gdaWmgphaUP2273ofs09wftxh2wttCeYr+vZP6Z33emO7vbz8z85jeziqqqKkIIIX7RdNoZQgghfnkk7IUQYhiQsBdCiGFAwl4IIYYBCXtxsWAQ5Lq9EL8oEvYikqrSXVqKv6wM1ePRtgohrlKKDL0UEYJBfAcP0v3ll6DTYZ4+HVNBARiN2kohxFVEwl5cktrRgb+yEvdHH6GLjWXEkiXoRo3SlgkhrhIS9qJPqs+H99NP6Vq3DuuiRUTdcw9KdDTopAdQiKuJhL3ol1BrK5533iHY3IzxppswTZmCPiVFWyaE+JmSsBf9Fwzir6nBV1xMoLoaU2Eh5rvuQjdiBKHWVnSxsdK3L8TPlIS9GDi/n1BLC66338Z/9Cgj/vY3PB9/jOGaa7A+8oi2WgjxMyBhLy6bGgoROHoU5+rV+EpKUGJjSfjXvzDdeCPo9aCqhJxOgidPEqiuJlBfj2K1YrTZMEyYgH7UKDCbtasVQgwBCXtxRdTOTrrWrMH13nsQDGKaMoXYFSswZGfjKynBvWkT3fv3E2pvj1jOMH48ljvuIPrPf0afkRHRJoQYfBL24oqoXi+BmhpCnZ3hu26NeXl4P/uMrjffJNjQAED3mDH4k5LQdXdjbmxE39WFYjDAzTfT8Ze/0D1mjGbNYrBdf/312lliGJGwF4POs307nU89RaijA/3o0cQsW4Zl5kwwmUBVCTY10fXqq3i2bAFFwTR9OvGvvooSF6ddlRhEOhkuO6xJ2ItB5S8vp2PZMvwVFRhsNuJWr8Z0003aMgBcb76Jc80aVKcT64MPEvv889oSIcQgkV29GDSq14t3+3YCNTUoMTHErlr1g0EPEL1oEdHz5qEYjXg2b8b/zTfaEiHEIJGwF4Mm5HDg2bIF1e/HOn8+5ltv1ZZEUKKiiPrjHzHk5BByOnG+9pq2RAgxSCTsL0MoFCIYDEZMV9ob5vP58Hg8BINBbdNVw7tzJ8HmZnQpKUQ/+KC2+ZKMEyZg/vWvwWDAX1aGv6xMWyKEGARD0mevqiotLS34fL6I+Xq9nsTERIw/wV2WXV1dnDp1Cp1OR0ZGBlarFXpea3t7O6FQiKSkJO1iF2lvb+fYsWN0d3dHzM/KymLcuHER835MR0cHx48fB6CoqIhgMEh2djYZGRkYDAYKCgpQFEW72M9W6+zZ+A4dIupPfyJu1SqUnvf4x/iKi2l/+GFUj4eYJ5/EumSJtkQIcYX0K1euXKmdeaXOnz/Phx9+SG1tLcePHw9PBw4cQFEUxowZc1kjA/x+Py6XC/Nl3Ijz6aefcvz4cRoaGgiFQqSnpwNQX1/Pli1b8Pl82Gw27WIXOXHiBFVVVaSlpeF2uwmFQoRCIQwGAzqdDoPBgMFg0C52SYcOHWLfvn0cPnyYhoYG0tPTKSoqwu128/XXXzN58mSioqK0i/XJ6/USCAT6/RoGS8jpxPniixAKYV2wANOvfgU9O6rW1la+++47qqur8Xq9xMbG0tLSwogRIwDQJSbifu89Qu3t6NPSsPzmNxduyhJCDJqBJ24/tLe3o9PpmDdvXsR04sQJtm7dSllZ2WV1ezQ2NrJr1y7t7H6pqalh2rRp5Ofn09bWRjAYpLW1lQ0bNmA0GrmpjwuJ3xcMBhk5ciRNTU0cOXKE6upqqqurKSoq4t1332XHjh393jav10teXh75+flkZWXR1dVFdnY2t912G3FxcXgu48dDTp48ybZt23C73dqmAXnrrbd47bXXIqadO3dqy8ICFRWobje6hAT0Y8aEn4rZ0NDAxo0bOXv2LNHR0RQXF7N27Vp27NgRXlaxWjFedx2EQgSbmy+6AQvg22+/Db+vfr+fiooKbcmAffnllyxbtoz2nr/n9XpZt24du3bt6vMzPH36NKtXr9bOBqC5uZlNmzbhdDq1TUL8pIYk7AGcTifl5eUREz1dF01NTf3um1ZVFb/fj8/nw+v14nK58Pl8+Hy+Pv8htW6//fZwGJeVlWG329m4cSOpqanMnTuX+Ph47SJ9am5uZsaMGTz++OPh6b777qOlpYVAIKAtvyRVVYmNjWXBggWsWLGCp59+mhUrVlBYWIiiKAPavl6BQICDBw/y7LPPUlxcjNvtvqz1OJ1OysrKIqa+dj6h8+cBUEaMQOk5Yvd6vZSUlDB16lRmzZrFlClTKCwsxG63X7Su3rtoVa/3kr+QtXPnTl5++WXOnDmD3+9n/fr1rF+/nra2NkKhkLa8X4LBIG1tbdTX10PPwURxcTE6nY5AIBA+M3U4HIRCIc6cOUNDQwMOhwOHw0EwGKS5uRmPx4PL5aKqqoq6urpwt6DD4aCqqoqamhq8Xi9Op5Ouri66urpobW0N13g8Hs6dO8epU6c4efLkRV2EWmVlZdTU1ITPKuvr6ykqKtKWCRFhSLpxWlpa2Lt3L1999RWHDx8OT71yc3PJycnpV1eO2+2muLiY0tJSqqqqaGxsxG63U1FRgc1m63f//+jRo5kwYQI2m42amhqqq6uZPHky06dPJyEhQVv+g86dO4fT6cThcJCZmUnK9x7z6/F4qKys5IYbbkDfj26Iuro6dDodY8eO1TZRXFxMfn4+sbGx2qY+2e12jhw5gsPh4OjRo7S3t5OSkkJMTMyA+v8PHjzI2bNnI+bl5ORw3XXXRczr5Tt4kO69e9GnphJ1993oU1JwuVxUVlZSWFiI1WolGAxit9tJTU1l/PjxpKamhpf37tmD/9tv0SUlYfntb9ElJkas/8CBA+GzqPj4eMrLy6mtreXEiROMHj2ahISEAW0fPTvszs5ODAYDNpuNffv2YTKZSE9PJyUlhXXr1rFjxw48Hg/Z2dk8+uijnDp1CqvVSkNDAz6fj/3795OUlMT777/P1q1bKS8vx+/3M2nSJNasWcOePXsoKirC5XJx/vx5Kisrqa2tZdu2beTn57N161Z0Oh3PPPMMdXV17Nq1i5EjR5KZmfmD2+Pz+di9ezeBQAC3282+ffsYO3YsaWlp2lIhwn48ba9Q75HzpEmTwvN+6Et8KUajkaysLPLy8sjKymLkyJHk5eWRl5fX76Cn5yi6o6MDu92Oz+fD5XKxd+9e7Ha7tvQXw2g0kpaWRnR0tLZp8PXuuL93FqEoSsQZSu9F56SkpIvO7JTez7KP74aiKFitVqxWa3jdsbGxA76u0UtRFHJzc7Hb7Rw+fJjKykrGjx8PPe+dx+Ohvr6ew4cP4/V6iY+P55FHHmHixIkcOHCAiooKFi9eTGxsLHV1daxdu5Zly5aRnJxMY2MjLpeLN954g1WrVlFaWkp6ejq1tbW4XC66urooKysjJiaGhIQE4uLiWL58ObNnzw6fGfyQjIwM7rnnHsrLy/n8888pLCyURyGIHzUkYd8b5nq9noKCAu644w4WLlwYbh9It4LJZMJms1FQUIDNZiMpKYmCggIKCgoGFPZbtmzhk08+obS0lOTkZJ544gmSk5N55513OHXqlLb8qjdhwgSee+457rrrrss66h0opefsSO3uRvV6ATCbzZjNZo4fPx7+zM+dOxc+eo3QE26K2YxisUS29bjzzjtZunQp1157LSaTiXnz5vHwww+Tnp5+2duXlJRERkYGL7zwAjNnzgx/pz7++GMWLFjAK6+8Qnp6OqqqEh0dHd6x3HzzzaiqSklJCVarlbNnz9LZ2Yndbuf8+fPEx8fT2NiI2+3GbrcTCATIzMzE7XZjsViYPn06H330ETabDb1ez6hRo4iJicFkMvXr4npycjILFy7k3nvvJT8/v19nkmJ4G5Kw7+2eCQaD1NbWcuzYMXbv3h1u1+v1l/XPaTabB9Tl8n2nT59m2rRpTJ48mYyMDCwWC4sWLWLMmDF88MEHNDU1aRe5pPz8fGbMmDGgHU1f/H4/brf7oqmvI7u+REdHM3v2bB577DFSUlIu630GKCgoYO7cuRFTX0NTDT1dMmpn54WHovV8XrfeeitVVVVs3ryZDRs28PbbbzNx4sTwaKhewZ5+cyU6+sLPHmo88MADzJkzB7PZjMFg4KmnnmLatGlXFHJxcXHEx8czadIkbrnlFsaPH09iYiIJCQnk5OSwdOlSnn/+eYxGIyaTiXHjxmEwGLBYLIwbN46HHnqIkpISysvLmT9/PnPmzGHdunVkZWUxevRo7r//fmbNmsVLL73EihUrsFqt5OfnEx8fz9SpUzGbzaSlpWGxWBg7diyKopCQkEBiYmK/Pjez2XxFOzoxvAzJOPvOzk727NlDR0cHABaLBZ/PRygUQq/XU1hYSG5u7oC/pIFAgO7u7vAY+YE4duwYpaWlWCwWbrzxRrKzs1EUhba2NoqLi0lJSen3iByAzZs343A4SE5ODs/rHfa4YMGCfoXQN998w6FDhyLW0aumpoYlS5YQN8CHg/XuJPpzPWQwqS4X5yZPRnW5iPv734leuDA8fLKjo4OGhgb8fj/XXHMNiYmJEa8v1NFBy+9+R7Cpiej584l74QXox9GtEKL/hiTs6Tli1fbL0tPFYzQa//9hpKo4HI5wP+/3/77f70dVVUwmU8Qyfem9APr9bdTr9eTm5l4yvC+lu7ub9vb2S3Zr9Z7aD3SH+FNqnTMH33//S9Ts2cT9858oMTHakkvq/uILHI89hurzEbN8OdbFi7UlQogrNGRhL4Yf9+bNdDz5JLqEBJK2b+/fj5KEQnT+4x+43noLXWIiIzdtujDmXggxqP6/h9fiF80ybRqGzExCbW10vfGGtvmS/GVldO/ff+FXrgoLJeiFGCIS9mLQKPHxRM2di2Iy4dm6Fe/27dqSCKrLhfvddwnU1aGLjydm6VJtiRBikEjYi0GjmExY7rwTQ14eqttN58qVdO/bpy0L63r9dTwffgiBANa//hVDbq62RAgxSKTPXgw67xdf0Ll8OcEzZ9ClpGBdvJiou+++MKRSVQnU1+P697/x/uc/YDBgmTmT+Bdf7PcFXSHEwEnYiyHh3b6drtdfx3/sGAD6zEx0qanQ3U3gxAlUpxPFZCJq1ixGPPEE+qws7SqEEINIwl4MGX95OZ7Nm/F89ln4QWm9DAUFRP/hD0T9/vfoRo2KaBNCDD4JezGk1GAQta0Nf3U1wfp6lBEjMObkoLfZUEymPp+FI4QYPBL2QggxDMhoHCGEGAYk7IUQYhiQsBdCiGFAwl4IIYYBCXshhBgGJOyFEGIYkLAXQohhQMJeCCGGgf8BIp2xzavfdkcAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "80c839b3-299a-47f6-ae09-7acab56fb25b",
   "metadata": {},
   "source": [
    "#### You can also use this button to reset your kernel\n",
    "\n",
    "![image.png](attachment:5db9e2e8-18f9-43d0-89a6-98c3bdbce362.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
